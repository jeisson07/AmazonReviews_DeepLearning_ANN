{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjmpHSU89SFV"
      },
      "source": [
        "# LSTM on Amazon fine food review"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "setofstopwords = set(stopwords.words('english'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRWs4wGw-JLH",
        "outputId": "2f3ccaf5-fd14-4248-91c5-3ce40216c63b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "6HKiV-Zk9SFb"
      },
      "outputs": [],
      "source": [
        "import sqlite3\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.manifold import TSNE\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer as sno\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zQt2w-y9i6r",
        "outputId": "f8823635-c291-4798-ddf5-3221de2955d6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0wqHcFg9SFg"
      },
      "source": [
        "### Loading from database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "XOuWKaIE9SFh"
      },
      "outputs": [],
      "source": [
        "data=pd.read_csv('/content/drive/MyDrive/Reviews.csv') "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 815
        },
        "id": "OGNxUQiG-wQ8",
        "outputId": "a65b7238-bb15-4389-9ab2-1194683ea821"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Id   ProductId          UserId                      ProfileName  \\\n",
              "0            1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
              "1            2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
              "2            3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
              "3            4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
              "4            5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
              "...        ...         ...             ...                              ...   \n",
              "568449  568450  B001EO7N10  A28KG5XORO54AY                 Lettie D. Carter   \n",
              "568450  568451  B003S1WTCU  A3I8AFVPEE8KI5                        R. Sawyer   \n",
              "568451  568452  B004I613EE  A121AA1GQV751Z                    pksd \"pk_007\"   \n",
              "568452  568453  B004I613EE   A3IBEVCTXKNOH          Kathy A. Welch \"katwel\"   \n",
              "568453  568454  B001LR2CU2  A3LGQPJCZVL9UC                         srfell17   \n",
              "\n",
              "        HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
              "0                          1                       1      5  1303862400   \n",
              "1                          0                       0      1  1346976000   \n",
              "2                          1                       1      4  1219017600   \n",
              "3                          3                       3      2  1307923200   \n",
              "4                          0                       0      5  1350777600   \n",
              "...                      ...                     ...    ...         ...   \n",
              "568449                     0                       0      5  1299628800   \n",
              "568450                     0                       0      2  1331251200   \n",
              "568451                     2                       2      5  1329782400   \n",
              "568452                     1                       1      5  1331596800   \n",
              "568453                     0                       0      5  1338422400   \n",
              "\n",
              "                                   Summary  \\\n",
              "0                    Good Quality Dog Food   \n",
              "1                        Not as Advertised   \n",
              "2                    \"Delight\" says it all   \n",
              "3                           Cough Medicine   \n",
              "4                              Great taffy   \n",
              "...                                    ...   \n",
              "568449                 Will not do without   \n",
              "568450                        disappointed   \n",
              "568451            Perfect for our maltipoo   \n",
              "568452  Favorite Training and reward treat   \n",
              "568453                         Great Honey   \n",
              "\n",
              "                                                     Text  \n",
              "0       I have bought several of the Vitality canned d...  \n",
              "1       Product arrived labeled as Jumbo Salted Peanut...  \n",
              "2       This is a confection that has been around a fe...  \n",
              "3       If you are looking for the secret ingredient i...  \n",
              "4       Great taffy at a great price.  There was a wid...  \n",
              "...                                                   ...  \n",
              "568449  Great for sesame chicken..this is a good if no...  \n",
              "568450  I'm disappointed with the flavor. The chocolat...  \n",
              "568451  These stars are small, so you can give 10-15 o...  \n",
              "568452  These are the BEST treats for training and rew...  \n",
              "568453  I am very satisfied ,product is as advertised,...  \n",
              "\n",
              "[568454 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4df27283-55b0-4537-9055-69d9a4683715\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>Time</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>B001E4KFG0</td>\n",
              "      <td>A3SGXH7AUHU8GW</td>\n",
              "      <td>delmartian</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1303862400</td>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "      <td>I have bought several of the Vitality canned d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>B00813GRG4</td>\n",
              "      <td>A1D87F6ZCVE5NK</td>\n",
              "      <td>dll pa</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1346976000</td>\n",
              "      <td>Not as Advertised</td>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>B000LQOCH0</td>\n",
              "      <td>ABXLMWJIXXAIN</td>\n",
              "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1219017600</td>\n",
              "      <td>\"Delight\" says it all</td>\n",
              "      <td>This is a confection that has been around a fe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>B000UA0QIQ</td>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>Karl</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1307923200</td>\n",
              "      <td>Cough Medicine</td>\n",
              "      <td>If you are looking for the secret ingredient i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>B006K2ZZ7K</td>\n",
              "      <td>A1UQRSCLF8GW1T</td>\n",
              "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1350777600</td>\n",
              "      <td>Great taffy</td>\n",
              "      <td>Great taffy at a great price.  There was a wid...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568449</th>\n",
              "      <td>568450</td>\n",
              "      <td>B001EO7N10</td>\n",
              "      <td>A28KG5XORO54AY</td>\n",
              "      <td>Lettie D. Carter</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1299628800</td>\n",
              "      <td>Will not do without</td>\n",
              "      <td>Great for sesame chicken..this is a good if no...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568450</th>\n",
              "      <td>568451</td>\n",
              "      <td>B003S1WTCU</td>\n",
              "      <td>A3I8AFVPEE8KI5</td>\n",
              "      <td>R. Sawyer</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1331251200</td>\n",
              "      <td>disappointed</td>\n",
              "      <td>I'm disappointed with the flavor. The chocolat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568451</th>\n",
              "      <td>568452</td>\n",
              "      <td>B004I613EE</td>\n",
              "      <td>A121AA1GQV751Z</td>\n",
              "      <td>pksd \"pk_007\"</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1329782400</td>\n",
              "      <td>Perfect for our maltipoo</td>\n",
              "      <td>These stars are small, so you can give 10-15 o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568452</th>\n",
              "      <td>568453</td>\n",
              "      <td>B004I613EE</td>\n",
              "      <td>A3IBEVCTXKNOH</td>\n",
              "      <td>Kathy A. Welch \"katwel\"</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1331596800</td>\n",
              "      <td>Favorite Training and reward treat</td>\n",
              "      <td>These are the BEST treats for training and rew...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568453</th>\n",
              "      <td>568454</td>\n",
              "      <td>B001LR2CU2</td>\n",
              "      <td>A3LGQPJCZVL9UC</td>\n",
              "      <td>srfell17</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1338422400</td>\n",
              "      <td>Great Honey</td>\n",
              "      <td>I am very satisfied ,product is as advertised,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>568454 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4df27283-55b0-4537-9055-69d9a4683715')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4df27283-55b0-4537-9055-69d9a4683715 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4df27283-55b0-4537-9055-69d9a4683715');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzRkyHKM9SFi"
      },
      "source": [
        "### Removing not helpful reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "jvNKvPNg9SFj",
        "outputId": "69d9f6e2-754d-4aed-b688-ceafefaa0056",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(393931, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "data['Score']=data['Score'].map(lambda x:'Positive' if x>3 else 'Negative')\n",
        "sorteddata= data.sort_values('ProductId',axis=0)\n",
        "finaldata= sorteddata.drop_duplicates(subset={'UserId','ProfileName',\\\n",
        "        'Time','Text'}, keep='first',inplace=False)\n",
        "\n",
        "finaldata= finaldata[finaldata['HelpfulnessNumerator'] <= finaldata['HelpfulnessDenominator']]\n",
        "data= finaldata.sort_values('Time',axis=0)\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-tBYhSo9SFk"
      },
      "source": [
        "### Cleaning HTML, punctuations, apply stemming, lowercasing etc without removing stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "YZThqIAe9SFl"
      },
      "outputs": [],
      "source": [
        "def cleanhtml(sentance): #substitute expression contained in <> with ' '\n",
        "    cleaned= re.sub(re.compile('<.*?>'),' ',sentance)\n",
        "    return cleaned\n",
        "#function for removing punctuations chars\n",
        "def cleanpunc(sentance):\n",
        "    cleaned= re.sub(r'[?|!|\\'|\"|#]',r'',sentance)\n",
        "    cleaned= re.sub(r'[.|,|)|(|\\|/]',r'',sentance)\n",
        "    return cleaned\n",
        "snowstem= sno('english')\n",
        "\n",
        "i=0\n",
        "str1=' '\n",
        "final_string=[]\n",
        "all_positive_words=[] # store words from +ve reviews here\n",
        "all_negative_words=[] # store words from -ve reviews here.\n",
        "for sent in data['Text'].values:\n",
        "    filtered_sentence=[]\n",
        "    #print(sent);\n",
        "    sent=cleanhtml(sent) # remove HTMl tags\n",
        "    for w in sent.split():\n",
        "        # we have used cleanpunc(w).split(), one more split function here \n",
        "        # because consider w=\"abc.def\", cleanpunc(w) will return \"abc def\"\n",
        "        # if we dont use .split() function then we will be considring \"abc def\" \n",
        "        # as a single word, but if you use .split() function we will get \"abc\", \"def\"\n",
        "        for cleaned_words in cleanpunc(w).split():\n",
        "            if((cleaned_words.isalpha()) & (len(cleaned_words)>2)):    \n",
        "                s=(snowstem.stem(cleaned_words.lower())).encode('utf8')\n",
        "                filtered_sentence.append(s)\n",
        "                if(data['Score'].values)[i] =='Positive':\n",
        "                    all_positive_words.append(s)\n",
        "                if(data['Score'].values)[i] =='Negative':\n",
        "                    all_negative_words.append(s)\n",
        "            else:\n",
        "                continue\n",
        "    str1 = b\" \".join(filtered_sentence) #final string of cleaned words\n",
        "    final_string.append(str1)\n",
        "\n",
        "# storing data till now\n",
        "data['CleanedText']=final_string \n",
        "#adding a column of CleanedText which displays the data after pre-processing of the review \n",
        "data['CleanedText']=data['CleanedText'].str.decode(\"utf-8\")\n",
        "    # store final table into an SQlLite table for future.\n",
        "data.to_csv('/content/drive/My Drive/vectors/processed_data.csv',index=False)\n",
        "# conn = sqlite3.connect('cleanedTextData.sqlite')\n",
        "# c=conn.cursor()\n",
        "# conn.text_factory = str\n",
        "# data.to_sql('Reviews', conn,  schema=None, if_exists='replace', \\\n",
        "#         index=True, index_label=None, chunksize=None, dtype=None)\n",
        "# conn.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "6Ay8yfCi9SFn",
        "outputId": "6a23b54c-c3a4-4d9a-89f1-4b4072ac0b96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 600
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Id   ProductId          UserId               ProfileName  \\\n",
              "150523  150524  0006641040   ACITT7DI6IDDL           shari zychinski   \n",
              "150500  150501  0006641040   AJ46FKXOVC7NR        Nicholas A Mesiano   \n",
              "451855  451856  B00004CXX9   AIUWLEQ1ADEG5          Elizabeth Medina   \n",
              "374358  374359  B00004CI84  A344SMIA5JECGM           Vincent P. Ross   \n",
              "451854  451855  B00004CXX9   AJH6LUC1UT1ON  The Phantom of the Opera   \n",
              "\n",
              "        HelpfulnessNumerator  HelpfulnessDenominator     Score       Time  \\\n",
              "150523                     0                       0  Positive  939340800   \n",
              "150500                     2                       2  Positive  940809600   \n",
              "451855                     0                       0  Positive  944092800   \n",
              "374358                     1                       2  Positive  944438400   \n",
              "451854                     0                       0  Positive  946857600   \n",
              "\n",
              "                                                  Summary  \\\n",
              "150523                          EVERY book is educational   \n",
              "150500  This whole series is great way to spend time w...   \n",
              "451855                               Entertainingl Funny!   \n",
              "374358                            A modern day fairy tale   \n",
              "451854                                         FANTASTIC!   \n",
              "\n",
              "                                                     Text  \\\n",
              "150523  this witty little book makes my son laugh at l...   \n",
              "150500  I can remember seeing the show when it aired o...   \n",
              "451855  Beetlejuice is a well written movie ..... ever...   \n",
              "374358  A twist of rumplestiskin captured on film, sta...   \n",
              "451854  Beetlejuice is an excellent and funny movie. K...   \n",
              "\n",
              "                                              CleanedText  \n",
              "150523  this witti littl book make son laugh loud reci...  \n",
              "150500  can rememb see the show when air televis year ...  \n",
              "451855  beetlejuic well written movi everyth about fro...  \n",
              "374358  twist rumplestiskin captur film star michael k...  \n",
              "451854  beetlejuic excel and funni movi keaton hilari ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-138b3439-367f-42b7-b172-52d6398a83dd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>Time</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "      <th>CleanedText</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>150523</th>\n",
              "      <td>150524</td>\n",
              "      <td>0006641040</td>\n",
              "      <td>ACITT7DI6IDDL</td>\n",
              "      <td>shari zychinski</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "      <td>939340800</td>\n",
              "      <td>EVERY book is educational</td>\n",
              "      <td>this witty little book makes my son laugh at l...</td>\n",
              "      <td>this witti littl book make son laugh loud reci...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150500</th>\n",
              "      <td>150501</td>\n",
              "      <td>0006641040</td>\n",
              "      <td>AJ46FKXOVC7NR</td>\n",
              "      <td>Nicholas A Mesiano</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>Positive</td>\n",
              "      <td>940809600</td>\n",
              "      <td>This whole series is great way to spend time w...</td>\n",
              "      <td>I can remember seeing the show when it aired o...</td>\n",
              "      <td>can rememb see the show when air televis year ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>451855</th>\n",
              "      <td>451856</td>\n",
              "      <td>B00004CXX9</td>\n",
              "      <td>AIUWLEQ1ADEG5</td>\n",
              "      <td>Elizabeth Medina</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "      <td>944092800</td>\n",
              "      <td>Entertainingl Funny!</td>\n",
              "      <td>Beetlejuice is a well written movie ..... ever...</td>\n",
              "      <td>beetlejuic well written movi everyth about fro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>374358</th>\n",
              "      <td>374359</td>\n",
              "      <td>B00004CI84</td>\n",
              "      <td>A344SMIA5JECGM</td>\n",
              "      <td>Vincent P. Ross</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Positive</td>\n",
              "      <td>944438400</td>\n",
              "      <td>A modern day fairy tale</td>\n",
              "      <td>A twist of rumplestiskin captured on film, sta...</td>\n",
              "      <td>twist rumplestiskin captur film star michael k...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>451854</th>\n",
              "      <td>451855</td>\n",
              "      <td>B00004CXX9</td>\n",
              "      <td>AJH6LUC1UT1ON</td>\n",
              "      <td>The Phantom of the Opera</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "      <td>946857600</td>\n",
              "      <td>FANTASTIC!</td>\n",
              "      <td>Beetlejuice is an excellent and funny movie. K...</td>\n",
              "      <td>beetlejuic excel and funni movi keaton hilari ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-138b3439-367f-42b7-b172-52d6398a83dd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-138b3439-367f-42b7-b172-52d6398a83dd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-138b3439-367f-42b7-b172-52d6398a83dd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "VkGQ5nPT9SFp",
        "outputId": "5f0133d8-8f87-44c2-d67c-66a04cf69447",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelatin with nuts - in this case Filberts. And it is cut into tiny squares and then liberally coated with powdered sugar.  And it is a tiny mouthful of heaven.  Not too chewy, and very flavorful.  I highly recommend this yummy treat.  If you are familiar with the story of C.S. Lewis\\' \"The Lion, The Witch, and The Wardrobe\" - this is the treat that seduces Edmund into selling out his Brother and Sisters to the Witch.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "data['Text'][2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "DxZYw8l99SFq",
        "outputId": "6a6247a7-fc25-4770-d7f8-1ccf02cad3f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'this confect that has been around few centuri light pillowi citrus gelatin with nut this case filbert and cut into tini squar and then liber coat with powder sugar and tini mouth heaven not too chewi and veri flavor high recommend this yummi treat you are familiar with the stori lion the witch and the this the treat that seduc edmund into sell out his brother and sister the witch'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "data['CleanedText'][2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "AimT0t889SFr"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWmIFRu39SFs"
      },
      "source": [
        "### Taking 100k datapoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "5OCAGoAi9SFs"
      },
      "outputs": [],
      "source": [
        "Data= data[:100000]\n",
        "Data= Data[['CleanedText','Score']]\n",
        "Data['Score']= Data['Score'].map(lambda x:1 if x=='Positive' else 0)\n",
        "\n",
        "Data_x= Data['CleanedText']\n",
        "Data_y= Data['Score']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "scrolled": true,
        "id": "mUmvp7by9SFt",
        "outputId": "7937eb21-f007-4d98-a131-731274a78743",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        this witti littl book make son laugh loud reci...\n",
              "1        can rememb see the show when air televis year ...\n",
              "2        beetlejuic well written movi everyth about fro...\n",
              "3        twist rumplestiskin captur film star michael k...\n",
              "4        beetlejuic excel and funni movi keaton hilari ...\n",
              "                               ...                        \n",
              "99995    was real happi find this store area carri nor ...\n",
              "99996    bought the wilton version these decor truffl h...\n",
              "99997    veri good wish quit pricey but certifi matter ...\n",
              "99998    have tri differ type and brand curri powder co...\n",
              "99999    unfortul due restrict the border crossingfrom ...\n",
              "Name: CleanedText, Length: 100000, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "Data_x.index= [i for i in range(0,10**5)]\n",
        "Data_x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHrYW_oU9SFu"
      },
      "source": [
        "### Making Vocabulary set and Frequency dictionary of words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "XyOsocj29SFu"
      },
      "outputs": [],
      "source": [
        "# collecting all words in single list\n",
        "list_= []\n",
        "for i in Data_x:\n",
        "    list_ += i\n",
        "list_= ''.join(list_)\n",
        "allWords=list_.split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "rVJIPrST9SFv"
      },
      "outputs": [],
      "source": [
        "vocabulary= set(allWords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "jVPSuOPX9SFw"
      },
      "outputs": [],
      "source": [
        "vocabulary_list= list(vocabulary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GcmtPIJj9SFw"
      },
      "outputs": [],
      "source": [
        "#frequency dictionary\n",
        "freq_dict= {}\n",
        "for word in vocabulary_list:\n",
        "    freq_dict[word]= allWords.count(word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqMCi6ya9SFx"
      },
      "outputs": [],
      "source": [
        "freq_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apQk1Sd29SFy"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('freq_dict.pkl','wb') as file:\n",
        "    pickle.dump(freq_dict,file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0FUL50T9SFz"
      },
      "source": [
        "### Creating rank list of frequent words upto 5000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWVLfpob9SFz"
      },
      "outputs": [],
      "source": [
        "from operator import itemgetter\n",
        "sorted_list= []\n",
        "for k, v in sorted(freq_dict.items(), key=itemgetter(1),reverse=True):\n",
        "    sorted_list.append(k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QdgED7X9SF0"
      },
      "outputs": [],
      "source": [
        "sorted_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "om9dAwB-9SF1"
      },
      "outputs": [],
      "source": [
        "Data_x[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WaIT1Pr89SF2"
      },
      "outputs": [],
      "source": [
        "top_words= 5000\n",
        "sorted_list= sorted_list[:5000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRjZefkv9SF3"
      },
      "source": [
        "### Transforming Sentences of words to sequence of rank number of words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05SSplCO9SF3"
      },
      "outputs": [],
      "source": [
        "column=[]\n",
        "for sent in Data_x:\n",
        "    lis=[]\n",
        "    for word in sent.split():\n",
        "        if word in sorted_list:\n",
        "            lis.append(word)\n",
        "    column.append(' '.join(lis))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXhoX8gw9SF4"
      },
      "outputs": [],
      "source": [
        "with open('column.pkl','wb') as file:\n",
        "    pickle.dump(column,file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8XIS26X9SF4"
      },
      "outputs": [],
      "source": [
        "final_x=[]\n",
        "for sent in Data_x:\n",
        "    lis=[]\n",
        "    for word in sent.split():\n",
        "        if word in sorted_list:\n",
        "            lis.append(sorted_list.index(word)+1)\n",
        "    final_x.append(lis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLnW4Hp39SF5"
      },
      "outputs": [],
      "source": [
        "Xtest= final_x[:30000]\n",
        "Ytest= Data_y[:30000]\n",
        "Xtrain= final_x[30000:]\n",
        "Ytrain= Data_y[30000:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMSGS_dS9SF5"
      },
      "outputs": [],
      "source": [
        "print(Xtrain[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmmkPMdT9SF6"
      },
      "source": [
        "## Applying LSTM models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0YcgXsso9SF6"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing import sequence\n",
        "max_review_length=600\n",
        "Xtrain = sequence.pad_sequences(Xtrain, maxlen=max_review_length)\n",
        "Xtest= sequence.pad_sequences(Xtest, maxlen=max_review_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vmkCZchk9SF7"
      },
      "outputs": [],
      "source": [
        "print(Xtrain[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_EqsDWk9SF8"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LX4a6XoB9SF8"
      },
      "outputs": [],
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2XT7sfOV9SF9"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "from keras.datasets import imdb\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM,Dropout\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "# fix random seed for reproducibility\n",
        "numpy.random.seed(7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHmPEOs29SF9"
      },
      "source": [
        "### Model 1 same as of IMDB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XzvPfDQ9SF-"
      },
      "outputs": [],
      "source": [
        "# create the model\n",
        "embedding_vecor_length = 32\n",
        "model = Sequential()\n",
        "model.add(Embedding(top_words+1, embedding_vecor_length, input_length=max_review_length))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWWQMQ0I9SF-"
      },
      "outputs": [],
      "source": [
        "history=  model.fit(Xtrain, Ytrain,\n",
        "          batch_size=64,\n",
        "          epochs=10,\n",
        "          verbose=1,\n",
        "          validation_data=(Xtest, Ytest))# Final evaluation of the model\n",
        "scores = model.evaluate(Xtest, Ytest, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1FyeP0tV9SF_"
      },
      "outputs": [],
      "source": [
        "#import pickle\n",
        "#with open('model.pkl','rb') as file:\n",
        "#    model=pickle.load(file)\n",
        "#with open('model2.pkl','rb') as file:\n",
        "#    model2=pickle.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0hYgA5p69SF_"
      },
      "outputs": [],
      "source": [
        "%matplotlib notebook\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "# https://gist.github.com/greydanus/f6eee59eaf1d90fcb3b534a25362cea4\n",
        "# https://stackoverflow.com/a/14434334\n",
        "# this function is used to update the plots for each epoch and error\n",
        "def plt_dynamic(x, vy, ty, ax, colors=['b']):\n",
        "    ax.plot(x, vy, 'b', label=\"Validation Loss\")\n",
        "    ax.plot(x, ty, 'r', label=\"Train Loss\")\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    fig.canvas.draw()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9GzVrQ1v9SGA"
      },
      "outputs": [],
      "source": [
        "score= model.evaluate(Xtest, Ytest, verbose=0)\n",
        "print('Test score: ',score[0])\n",
        "print('Test accuracy: ',score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rc0Kq0XH9SGB"
      },
      "outputs": [],
      "source": [
        "fig,ax = plt.subplots(1,1)\n",
        "ax.set_xlabel('epoch') ; ax.set_ylabel('Categorical Crossentropy Loss')\n",
        "x = list(range(1,11))\n",
        "vy = model.history.history['val_loss']\n",
        "ty = model.history.history['loss']\n",
        "plt_dynamic(x, vy, ty, ax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIw-nLx49SGB"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2ZbSXW_9SGC"
      },
      "source": [
        "### Model 2 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQ0Y9lUq9SGC"
      },
      "outputs": [],
      "source": [
        "# create the model\n",
        "embedding_vecor_length = 32\n",
        "model2 = Sequential()\n",
        "model2.add(Embedding(top_words+1, embedding_vecor_length, input_length=max_review_length))\n",
        "model2.add(LSTM(100,return_sequences=True))\n",
        "model2.add(Dropout(0.25))\n",
        "model2.add(LSTM(80))\n",
        "model2.add(Dropout(0.5))\n",
        "model2.add(Dense(1, activation='sigmoid'))\n",
        "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model2.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jw5PnImS9SGD"
      },
      "outputs": [],
      "source": [
        "history2=  model2.fit(Xtrain, Ytrain,\n",
        "          batch_size=64,\n",
        "          epochs=10,\n",
        "          verbose=1,\n",
        "          validation_data=(Xtest, Ytest))# Final evaluation of the model\n",
        "scores = model2.evaluate(Xtest, Ytest, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDSwFmpc9SGE"
      },
      "outputs": [],
      "source": [
        "score= model2.evaluate(Xtest, Ytest, verbose=0)\n",
        "print('Test score: ',score[0])\n",
        "print('Test accuracy: ',score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SugFpOdX9SGE"
      },
      "outputs": [],
      "source": [
        "fig,ax = plt.subplots(1,1)\n",
        "ax.set_xlabel('epoch') ; ax.set_ylabel('Categorical Crossentropy Loss')\n",
        "x = list(range(1,11))\n",
        "vy = model2.history.history['val_loss']\n",
        "ty = model2.history.history['loss']\n",
        "plt_dynamic(x, vy, ty, ax)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mD7Gw5ht9SGF"
      },
      "source": [
        "## Testing our model on self made review sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VUIPVxmR9SGF"
      },
      "outputs": [],
      "source": [
        "# making a function which convert sentance to requred vectorized format that will feed well in model\n",
        "\n",
        "def cleanhtml(sentance): #substitute expression contained in <> with ' '\n",
        "    cleaned= re.sub(re.compile('<.*?>'),' ',sentance)\n",
        "    return cleaned\n",
        "#function for removing punctuations chars\n",
        "def cleanpunc(sentance):\n",
        "    cleaned= re.sub(r'[?|!|\\'|\"|#]',r'',sentance)\n",
        "    cleaned= re.sub(r'[.|,|)|(|\\|/]',r'',sentance)\n",
        "    return cleaned\n",
        "snowstem= sno('english')\n",
        "\n",
        "def predict_this(sentance):\n",
        "    i=0\n",
        "    str1=' '\n",
        "    final_string=[]\n",
        "    all_positive_words=[] # store words from +ve reviews here\n",
        "    all_negative_words=[] # store words from -ve reviews here.\n",
        "    sent= sentance\n",
        "    filtered_sentence=[]\n",
        "    #print(sent);\n",
        "    sent=cleanhtml(sent) # remove HTMl tags\n",
        "    for w in sent.split():\n",
        "        # we have used cleanpunc(w).split(), one more split function here \n",
        "        # because consider w=\"abc.def\", cleanpunc(w) will return \"abc def\"\n",
        "        # if we dont use .split() function then we will be considring \"abc def\" \n",
        "        # as a single word, but if you use .split() function we will get \"abc\", \"def\"\n",
        "        for cleaned_words in cleanpunc(w).split():\n",
        "            if((cleaned_words.isalpha()) & (len(cleaned_words)>2)):    \n",
        "                s=(snowstem.stem(cleaned_words.lower())).encode('utf8')\n",
        "                filtered_sentence.append(s)\n",
        "                if(data['Score'].values)[i] =='Positive':\n",
        "                    all_positive_words.append(s)\n",
        "                if(data['Score'].values)[i] =='Negative':\n",
        "                    all_negative_words.append(s)\n",
        "            else:\n",
        "                continue\n",
        "    str1 = b\" \".join(filtered_sentence) #final string of cleaned words\n",
        "    final_string.append(str1)\n",
        "\n",
        "    final_string\n",
        "    for i in final_string:\n",
        "        final_string=i.decode(\"utf-8\")\n",
        "\n",
        "    lis=[]\n",
        "    for word in final_string.split():\n",
        "        if word in sorted_list:\n",
        "            lis.append(sorted_list.index(word)+1)\n",
        "\n",
        "    final_string= lis\n",
        "    final_string = sequence.pad_sequences([final_string], maxlen=max_review_length)\n",
        "    print(final_string)\n",
        "    what= ''\n",
        "    if (round(float(model2.predict(final_string)))==1):\n",
        "        what= 'Positive'\n",
        "        acc= round(float(model2.predict(final_string))*100,2)\n",
        "    else:\n",
        "        what='Negative'\n",
        "        acc= 100- round(float(model2.predict(final_string))*100,2)\n",
        "    print(what,'review with',acc,'% Accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "iF6FqyoL9SGG"
      },
      "outputs": [],
      "source": [
        "sentance= 'food was very bad in taste'\n",
        "predict_this(sentance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KwWNv1Oy9SGH"
      },
      "outputs": [],
      "source": [
        "sentance= 'taste of chocolate was fantastic'\n",
        "predict_this(sentance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHCl2q539SGH"
      },
      "outputs": [],
      "source": [
        "sentance= 'food was medium tasty'\n",
        "predict_this(sentance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJVuZ5_V9SGI"
      },
      "outputs": [],
      "source": [
        "print(data['Text'][1])\n",
        "predict_this(data['Text'][1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PW2o6HE9SGI"
      },
      "source": [
        "# Summary \n",
        "\n",
        "* Accuracy of First model is 93.13%\n",
        "* Accuracy of Second model is 92.95%"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "notify_time": "5",
    "colab": {
      "name": "DeepLearning.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}